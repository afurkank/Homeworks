# Deep Meta-Learning: Learning to Learn in the Concept Space

## Objective

The primary goal of the paper is to enhance the effectiveness of meta-learning, particularly in the context of few-shot learning. The authors aim to integrate the representation power of deep learning into meta-learning, proposing a new framework known as Deep Meta-Learning (DEML). This framework is designed to operate in the "concept space," moving away from the more complicated instance space commonly used in meta-learning. The core objective is to improve the performance of few-shot learning tasks by leveraging this new approach​​.

## Background

Meta-learning, or learning to learn, has been a significant focus within machine learning, especially for tasks that involve limited data, like few-shot learning. Traditional meta-learning works at the task level rather than on individual instances, learning task-agnostic algorithms that can quickly adapt to new tasks. However, despite its potential, meta-learning has not fully realized its effectiveness, particularly in few-shot learning scenarios. One major limitation identified by the authors is the lack of efficient data representation in meta-learning. The paper seeks to address this gap by leveraging the capabilities of deep learning for better representation in meta-learning​​.

## Methods and Methodologies

The DEML framework proposed in the paper is based on three key components:

- Concept Generator (G): This is a deep neural network, which can be any popular convolutional neural network. Its function is to extract task-agnostic, meta-level representations from the data, capturing the high-level concepts of instances from various related tasks.

- Meta-Learner (M): The meta-learner, parameterized by θM, is responsible for the actual learning process. It learns to create a learner for each task based on the training data. The paper allows for flexibility in the choice of existing meta-learners, such as Matching Nets, MAML, or Meta-SGD, to be integrated into this framework.

- Concept Discriminator (D): Parameterized by θD, the concept discriminator is designed to predict labels for concepts generated by the Concept Generator. This component can be implemented using various supervised learning methods​​.

The DEML framework works by jointly training these three modules. The concept generator develops representations that capture the concepts of the data, while the meta-learner uses these representations for few-shot learning. The concept discriminator aids in enhancing the concept generator by handling concept discrimination tasks on large-scale external datasets.

The learning process involves two pipelines: concept discrimination and meta-learning. Both are trained together in a learning-to-learn manner to optimize a combined loss function. The concept generator is trained to generate representations for samples (capturing their concepts), and the concept discriminator is trained to discriminate these concepts. The meta-learner, meanwhile, is trained to perform few-shot learning in the high-level concept space​​.

# Conclusion

In summary, the paper introduces a novel framework for improving meta-learning by integrating the representation power of deep learning. This approach moves meta-learning from the raw instance space to a more abstract concept space, enabling more effective few-shot learning. The paper's experiments demonstrate significant improvements over traditional meta-learning approaches, indicating the potential of this new methodology in enhancing the generalization capability of meta-learners​​.

# Paper link
https://arxiv.org/abs/1802.03596
